# Dialectical MCP Server Environment Configuration

# LLM Provider Configuration
# Options: openai, anthropic, mock
LLM_PROVIDER=mock

# API Key (required for openai/anthropic)
# For OpenAI: sk-...
# For Anthropic: sk-ant-...
LLM_API_KEY=

# Model Selection (optional, defaults shown)
# OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
LLM_MODEL=

# Optional: Custom API base URL (for OpenAI-compatible endpoints)
LLM_BASE_URL=

# Server Configuration
# Maximum session age in milliseconds (default: 24 hours)
MAX_SESSION_AGE=86400000

# Logging level (debug, info, warn, error)
LOG_LEVEL=info